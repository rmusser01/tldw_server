# file: /Users/appledev/Working/tldw_server/tldw_Server_API/app/core/LLM_Calls/Summarization_General_Lib.py
# hypothesis_version: 6.135.11

[0.1, 0.2, 0.3, 0.5, 0.7, 1.0, 120, 200, 429, 500, 502, 503, 504, 4096, '\n\n---\n\n', '\n\nHuman:', '...', '/chat/completions', '2023-06-01', 'Accept', 'Authorization', 'Content-Type', 'Error:', 'Generator consumed.', 'No summary available', 'No title available', 'None', 'Text', 'Unknown author', 'Unknown error', '[', '[DONE]', 'accept', 'anthropic', 'anthropic-version', 'anthropic_api', 'api_base_url', 'api_key', 'api_retries', 'api_retry_delay', 'api_timeout', 'application/json', 'author', 'choices', 'cohere', 'cohere_api', 'content', 'content-type', 'content_block_delta', 'custom-openai-api', 'custom-openai-api-2', 'data:', 'data: ', 'deepseek', 'deepseek-chat', 'deepseek_api', 'delta', 'description', 'event:', 'example_user_id', 'gemini-1.5-pro', 'generated_text', 'google', 'google_api', 'gpt-4o', 'groq', 'groq_api', 'http://', 'https://', 'huggingface', 'huggingface_api', 'inputs', 'kobold', 'llama.cpp', 'local-llm', 'max_size', 'max_tokens', 'message', 'messages', 'metadata', 'method', 'mistral', 'mistral-large-latest', 'mistral_api', 'mock-llm', 'model', 'none', 'ollama', 'ooba', 'openai', 'openai_api', 'openrouter', 'openrouter_api', 'overlap', 'preamble', 'r', 'response', 'role', 'safe_prompt', 'segments', 'sentences', 'stop_sequences', 'stream', 'streaming', 'summary', 'system', 'tabbyapi', 'temperature', 'text', 'text/event-stream', 'title', 'token', 'top_k', 'top_p', 'transcription', 'type', 'user', 'user_id', 'utf-8', 'vllm', 'x-api-key', '{']